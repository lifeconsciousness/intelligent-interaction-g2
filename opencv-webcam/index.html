<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>Face and Eye Detection with OpenCV.js</title>
    <script async src="opencv.js"></script> <!-- Ensure opencv.js is included -->
    <script src="utils.js"></script> <!-- Include utils.js here -->
</head>

<body>
    <h2>Face and Eye Detection using OpenCV.js</h2>
    <p id="status">OpenCV.js is loading...</p>
    <div>
        <video id="videoStream" width="640" height="480" autoplay></video>
        <canvas id="outputCanvas" width="640" height="480"></canvas>
    </div>

    <script type="text/javascript">
        var isStreaming = true; // Variable to control video streaming
        var utils; // Declare a variable to hold the Utils reference

        var Module = {
            onRuntimeInitialized() {
                document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
                initializeOpenCV();
            }
        };

        function initializeOpenCV() {
            console.log("OpenCV.js is ready");
            // Initialize utils here, assuming Utils is a class defined in utils.js
            utils = new Utils(); // Create a new instance of Utils

            let videoStream = document.getElementById('videoStream');
            let inputMatrix = new cv.Mat(videoStream.height, videoStream.width, cv.CV_8UC4);
            let outputMatrix = new cv.Mat(videoStream.height, videoStream.width, cv.CV_8UC4);
            let grayMatrix = new cv.Mat();
            let videoCapture = new cv.VideoCapture(videoStream);
            let detectedFaces = new cv.RectVector();
            let detectedEyes = new cv.RectVector();
            let faceDetector = new cv.CascadeClassifier();
            let eyeDetector = new cv.CascadeClassifier();

            // Load Haar Cascade classifiers for face and eyes
            Promise.all([
                loadCascadeFile(faceDetector, "haarcascade_frontalface_default.xml"),
                loadCascadeFile(eyeDetector, "haarcascade_eye_tree_eyeglasses.xml")
            ]).then(() => {
                initCamera().then(() => {
                    console.log("Webcam streaming started.");
                    processVideo(videoCapture, inputMatrix, outputMatrix, grayMatrix, detectedFaces, detectedEyes, faceDetector, eyeDetector);
                });
            }).catch(error => {
                console.error("Error loading classifier:", error);
            });
        }

        function loadCascadeFile(classifier, url) {
            return new Promise((resolve, reject) => {
                // Use createFileFromUrl to pre-load the XML
                utils.createFileFromUrl(url, url, () => {
                    classifier.load(url); // Load the cascade from the file
                    resolve();
                });
            });
        }

        function initCamera() {
            return new Promise((resolve, reject) => {
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(stream => {
                        document.getElementById('videoStream').srcObject = stream;
                        resolve();
                    })
                    .catch(err => {
                        console.error("Error accessing webcam:", err);
                        reject(err);
                    });
            });
        }

        function processVideo(videoCapture, inputMatrix, outputMatrix, grayMatrix, detectedFaces, detectedEyes, faceDetector, eyeDetector) {
            const FPS = 60;
            function detectAndDraw() {
                if (!isStreaming) {
                    // Clean up
                    inputMatrix.delete();
                    outputMatrix.delete();
                    grayMatrix.delete();
                    detectedFaces.delete();
                    detectedEyes.delete();
                    faceDetector.delete();
                    eyeDetector.delete();
                    return;
                }

                videoCapture.read(inputMatrix); // Read frame from video
                inputMatrix.copyTo(outputMatrix); // Copy source to destination
                cv.cvtColor(outputMatrix, grayMatrix, cv.COLOR_RGBA2GRAY); // Convert to grayscale

                // Detect faces
                faceDetector.detectMultiScale(grayMatrix, detectedFaces, 1.1, 3, 0);

                // Draw rectangles around detected faces
                for (let i = 0; i < detectedFaces.size(); ++i) {
                    let face = detectedFaces.get(i);
                    let point1 = new cv.Point(face.x, face.y);
                    let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                    cv.rectangle(outputMatrix, point1, point2, [255, 0, 0, 255]); // Draw face rectangle

                    // Detect eyes within the face region
                    let faceROI = grayMatrix.roi(face);
                    eyeDetector.detectMultiScale(faceROI, detectedEyes, 1.1, 3, 0);

                    for (let j = 0; j < detectedEyes.size(); ++j) {
                        let eye = detectedEyes.get(j);
                        let eyePoint1 = new cv.Point(face.x + eye.x, face.y + eye.y);
                        let eyePoint2 = new cv.Point(face.x + eye.x + eye.width, face.y + eye.y + eye.height);
                        cv.rectangle(outputMatrix, eyePoint1, eyePoint2, [0, 255, 0, 255]); // Draw eye rectangle
                    }

                    faceROI.delete(); // Clean up ROI
                }

                // Show the processed frame
                cv.imshow('outputCanvas', outputMatrix);

                // Schedule the next frame processing
                setTimeout(detectAndDraw, 1000 / FPS);
            }

            // Start processing when the video is playing
            videoStream.addEventListener('play', () => {
                detectAndDraw();
            });
        }
    </script>
</body>

</html>